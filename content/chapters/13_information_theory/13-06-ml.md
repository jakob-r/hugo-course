---
title: "Chapter 13.6: Information Theory for Machine Learning"
---
In this section, we discuss how information-theoretic concepts are used in machine learning and demonstrate the equivalence of KL minimization and maximum likelihood maximization, as well as how (cross-)entropy can be used as a loss function. 

<!--more-->

### Lecture video

{{< video id="GX4HwGpbkFw" >}}

### Lecture slides

{{< pdfjs file="slides-info-ml.pdf" >}}
